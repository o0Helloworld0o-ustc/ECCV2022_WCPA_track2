{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e779dcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "from renderer import QuickRenderer\n",
    "\n",
    "seed = 777\n",
    "np.random.seed(seed)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ba3768",
   "metadata": {},
   "source": [
    "# Prerequisite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d6011e",
   "metadata": {},
   "source": [
    "Firstly, set the root directory of your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157d8655",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = Path('E:\\WCPA_track2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7998d7bb",
   "metadata": {},
   "source": [
    "Read the list of the training instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c50bb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = data_root / 'list/WCPA_track2_train.csv'\n",
    "df = pd.read_csv(csv_path, dtype={'subject_id': str, 'img_id': str})\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab618bb",
   "metadata": {},
   "source": [
    "Read the global projection matrix (OpenGL format), which is used to covert vertices from camera space to NDC space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fe76d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_path = data_root / 'resources/projection_matrix.txt'\n",
    "M_proj = np.loadtxt(txt_path, dtype=np.float32)\n",
    "print(M_proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1509bb1",
   "metadata": {},
   "source": [
    "We provide a example of 3D mesh. You can open it using Meshlab for more details. Note that the left side of the face points to the $+x$ direction, the top of the face points to the $+y$ direction, and the face looks to the $+z$ direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb9f2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_path = data_root / 'resources/example.obj'\n",
    "mesh = trimesh.load(obj_path, process=False)\n",
    "verts_template = np.array(mesh.vertices, dtype=np.float32)\n",
    "tris = np.array(mesh.faces, dtype=np.int32)\n",
    "print(verts_template.shape, tris.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d8031f",
   "metadata": {},
   "source": [
    "We also provide indices of 68 landmarks from 1,220 vertices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3104ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "npy_path = data_root / 'resources/kpt_ind.npy'\n",
    "kpt_ind = np.load(npy_path)\n",
    "print(kpt_ind.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513287d3",
   "metadata": {},
   "source": [
    "A quick renderer is implemented for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bedf1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_h, img_w = 800, 800   # All images are the same size\n",
    "renderer = QuickRenderer(img_w, img_h, M_proj, tris)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa9dd4f",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbde0287",
   "metadata": {},
   "source": [
    "Render template mesh with difference rotation and translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dffb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 5, figsize=(26, 16))\n",
    "\n",
    "titles = ['zero R/t', 'R_x > 0', 'R_x < 0', 'R_y > 0', 'R_y < 0', 'R_z > 0', 'R_z < 0',\n",
    "          't_x > 0', 't_x < 0', 't_y > 0', 't_y < 0', '|t_z| is larger', '|t_z| is smaller']\n",
    "\n",
    "default_t = np.array([0, 0, -0.45])\n",
    "\n",
    "for k in range(len(titles)):\n",
    "\n",
    "    R_t = np.identity(4)\n",
    "    R_t[3, :3] = default_t\n",
    "    \n",
    "    if k == 0:\n",
    "        None\n",
    "\n",
    "    elif k == 1:\n",
    "        R_t[:3, :3] = Rotation.from_euler('x', 30, degrees=True).as_matrix().T\n",
    "    \n",
    "    elif k == 2:\n",
    "        R_t[:3, :3] = Rotation.from_euler('x', -30, degrees=True).as_matrix().T\n",
    "\n",
    "    elif k == 3:\n",
    "        R_t[:3, :3] = Rotation.from_euler('y', 30, degrees=True).as_matrix().T\n",
    "  \n",
    "    elif k == 4:\n",
    "        R_t[:3, :3] = Rotation.from_euler('y', -30, degrees=True).as_matrix().T\n",
    "        \n",
    "    elif k == 5:\n",
    "        R_t[:3, :3] = Rotation.from_euler('z', 30, degrees=True).as_matrix().T\n",
    "        \n",
    "    elif k == 6:\n",
    "        R_t[:3, :3] = Rotation.from_euler('z', -30, degrees=True).as_matrix().T\n",
    "\n",
    "    elif k == 7:\n",
    "        R_t[3, 0] += 0.12\n",
    "        \n",
    "    elif k == 8:\n",
    "        R_t[3, 0] -= 0.12\n",
    "        \n",
    "    elif k == 9:\n",
    "        R_t[3, 1] += 0.12\n",
    "        \n",
    "    elif k == 10:\n",
    "        R_t[3, 1] -= 0.12\n",
    "        \n",
    "    elif k == 11:\n",
    "        R_t[3, 2] += 0.2\n",
    "\n",
    "    elif k == 12:\n",
    "        R_t[3, 2] -= 0.2\n",
    "    \n",
    "    img_render = renderer(verts_template, R_t)\n",
    "    axes.flat[k].imshow(img_render)\n",
    "    axes.flat[k].axis('off')\n",
    "    axes.flat[k].set_title(titles[k])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c410ce",
   "metadata": {},
   "source": [
    "Plot some images with corresponding 2D 68 landmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade04607",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 5, figsize=(32, 32))\n",
    "\n",
    "for k, ax in enumerate(axes.flat):\n",
    "    index = np.random.randint(len(df))\n",
    "\n",
    "    subject_id = df['subject_id'][index]\n",
    "    facial_action = df['facial_action'][index]\n",
    "    img_id = df['img_id'][index]\n",
    "\n",
    "    img_path = data_root / 'image' / subject_id / facial_action / f'{img_id}_ar.jpg'\n",
    "    txt_path = data_root / '68landmarks' / subject_id / facial_action / f'{img_id}_68landmarks.txt'\n",
    "\n",
    "    img = cv2.imread(str(img_path))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    pts68 = np.loadtxt(txt_path, dtype=np.int32)\n",
    "\n",
    "    for p in pts68:\n",
    "        cv2.circle(img, (p[0], p[1]), radius=4, color=(0, 255, 0), thickness=-1)\n",
    "\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bc3754",
   "metadata": {},
   "source": [
    "Read the images and its ground truth of 3D vertices and face pose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba79af18",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 5, figsize=(32, 32))\n",
    "\n",
    "for k, ax in enumerate(axes.flat):\n",
    "    index = np.random.randint(len(df))\n",
    "\n",
    "    subject_id = df['subject_id'][index]\n",
    "    facial_action = df['facial_action'][index]\n",
    "    img_id = df['img_id'][index]\n",
    "\n",
    "    img_path = data_root / 'image' / subject_id / facial_action / f'{img_id}_ar.jpg'\n",
    "    npz_path = data_root / 'info' / subject_id / facial_action / f'{img_id}_info.npz'\n",
    "\n",
    "    img = cv2.imread(str(img_path))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    M = np.load(npz_path)\n",
    "\n",
    "    img_render = renderer(M['verts'], M['R_t'], overlap=img) \n",
    "    ax.imshow(img_render)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50772b4",
   "metadata": {},
   "source": [
    "Understand the transformation pipeline from world space to image space and index 68 landmarks from 1,220 vertices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255743d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 3, figsize=(32, 32))\n",
    "\n",
    "for k, ax in enumerate(axes.flat):\n",
    "    index = np.random.randint(len(df))\n",
    "\n",
    "    subject_id = df['subject_id'][index]\n",
    "    facial_action = df['facial_action'][index]\n",
    "    img_id = df['img_id'][index]\n",
    "\n",
    "    img_path = data_root / 'image' / subject_id / facial_action / f'{img_id}_ar.jpg'\n",
    "    npz_path = data_root / 'info' / subject_id / facial_action / f'{img_id}_info.npz'\n",
    "\n",
    "    img = cv2.imread(str(img_path))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_h, img_w, _ = img.shape\n",
    "    M = np.load(npz_path)\n",
    "\n",
    "\n",
    "    verts3d, R_t = M['verts'], M['R_t']\n",
    "    ones = np.ones([verts3d.shape[0], 1])\n",
    "    verts_homo = np.concatenate([verts3d, ones], axis=1)\n",
    "\n",
    "    assert R_t[3, 2] < 0    # tz is always negative\n",
    "\n",
    "    M1 = np.array([\n",
    "        [img_w/2,       0, 0, 0],\n",
    "        [      0, img_h/2, 0, 0],\n",
    "        [      0,       0, 1, 0],\n",
    "        [img_w/2, img_h/2, 0, 1]\n",
    "    ])\n",
    "\n",
    "    # world space -> camera space -> NDC space -> image space\n",
    "    verts = verts_homo @ R_t @ M_proj @ M1\n",
    "    w_ = verts[:, [3]]\n",
    "    verts = verts / w_\n",
    "\n",
    "    # image space: →+x，↓+y\n",
    "    points2d = verts[:, :2]\n",
    "    points2d[:, 1] = img_h - points2d[:, 1]\n",
    "\n",
    "    temp1 = img.copy()\n",
    "    for p in points2d:\n",
    "        cv2.circle(temp1, (int(p[0]), int(p[1])), radius=2, color=(0, 255, 0), thickness=-1)\n",
    "\n",
    "    temp2 = img.copy()\n",
    "    for p in points2d[kpt_ind]:\n",
    "        cv2.circle(temp2, (int(p[0]), int(p[1])), radius=4, color=(0, 255, 0), thickness=-1)\n",
    "\n",
    "    img_display = np.hstack([temp1, temp2])\n",
    "\n",
    "    ax.imshow(img_display)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
